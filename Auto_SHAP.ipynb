{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ce8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.makedirs(\"plots/rmplots\", exist_ok=True)\n",
    "os.makedirs(\"plots/rmplots/SHAP\", exist_ok=True)\n",
    "\n",
    "ds = pd.read_csv(\"crop_yield_dataset.csv\")\n",
    "ds[\"Date\"] = pd.to_datetime(ds[\"Date\"])\n",
    "ds[\"Year\"] = ds[\"Date\"].dt.year\n",
    "ds[\"Month\"] = ds[\"Date\"].dt.month\n",
    "\n",
    "crops = ds[\"Crop_Type\"].unique()\n",
    "summary_list = []  # to collect results\n",
    "\n",
    "for crop in crops:\n",
    "    print(f\"Processing {crop}...\")\n",
    "\n",
    "    # Subset dataset\n",
    "    crop_ds = ds[ds[\"Crop_Type\"] == crop]\n",
    "    X = crop_ds[[\"Soil_Quality\", \"Temperature\", \"Humidity\", \"N\", \"P\", \"K\", \"Soil_pH\"]]\n",
    "    y = crop_ds[\"Crop_Yield\"]\n",
    "\n",
    "    # Train/test split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=36)\n",
    "\n",
    "    # Train model\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=36)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # SHAP (subset for speed)\n",
    "    X_sample = X_test.sample(100, random_state=36) if len(X_test) > 100 else X_test\n",
    "    explainer = shap.TreeExplainer(rf)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "    y_sample = y.loc[X_sample.index]  # align yields with sampled rows\n",
    "\n",
    "    # Get indices for min, median, max Crop Yield\n",
    "    low_idx = y_sample.idxmin()\n",
    "    high_idx = y_sample.idxmax()\n",
    "    median_idx = y_sample.sort_values().index[len(y_sample)//2]\n",
    "\n",
    "    # Collect mean absolute SHAP values (feature importance)\n",
    "    shap_importance = pd.DataFrame({\n",
    "        \"Feature\": X_sample.columns,\n",
    "        \"MeanAbsSHAP\": np.abs(shap_values).mean(axis=0)\n",
    "    })\n",
    "    shap_importance[\"Crop_Type\"] = crop\n",
    "    summary_list.append(shap_importance)\n",
    "\n",
    "    for label, idx in [(\"low\", low_idx), (\"median\", median_idx), (\"high\", high_idx)]:\n",
    "        row_i = X_sample.loc[idx]\n",
    "        shap_i = shap_values[list(X_sample.index).index(idx)]\n",
    "    \n",
    "        shap_html = shap.force_plot(\n",
    "            explainer.expected_value,\n",
    "            shap_i,\n",
    "            row_i,\n",
    "            matplotlib=False\n",
    "        )\n",
    "        shap.save_html(f\"plots/rmplots/SHAP/{crop}_shap_force_{label}.html\", shap_html)\n",
    "\n",
    "\n",
    "# Combine all crops into one CSV\n",
    "summary_df = pd.concat(summary_list, ignore_index=True)\n",
    "summary_df.to_csv(\"plots/rmplots/SHAP/shap_summary_table.csv\", index=False)\n",
    "\n",
    "print(\"Done! Plots and CSV saved in plots/rmplots/html/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vLLM)",
   "language": "python",
   "name": "vllm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
